from io import StringIO
import zipfile
import pandas as pd
import requests
import io
import os
from tqdm import tqdm

# Yard Express Url
url = 'http://yardexpress-daily.s3.amazonaws.com/yardexpress_{}.csv'

# Depot Names
abbrevation = {'Depot': ['BAISLEY PARK', 'CASTLETON', "CHARLESTON", "COLLEGE POINT", "CASEY STENGEL", "EASTCHESTER",
                         "EAST NEW YORK", "FLATBUSH",
                         "FRESH POND", "FAR ROCKAWAY", "GRAND AV", "GUN HILL", "JAMAICA", "JACKIE GLEASON", "JFK",
                         "KINGSBRIDGE", "LA GUARDIA",
                         "MEREDITH AV", "MIKE QUILL", "MANHATTANVILLE", "MOTHER HALE", "TUSKEGEE AIRMEN",
                         "QUEENS VILLAGE", "SPRING CREEK",
                         "ULMER PARK", "WEST FARMS", "YONKERS", "YUKON"],
               'Division': ["Queens South", "Staten Island", "Staten Island", "Queens North", "Queens North", "Bronx",
                            "Brooklyn",
                            "Brooklyn", "Brooklyn", "Queens South", "Brooklyn", "Bronx", "Queens North", "Brooklyn",
                            "Queens South", "Bronx",
                            "Queens North", "Staten Island", "Manhattan", "Manhattan", "Manhattan", "Manhattan",
                            "Queens North", "Brooklyn",
                            "Brooklyn", "Bronx", "Bronx", "Staten Island"]}

depot = pd.DataFrame(abbrevation,
                     index=["BP", "CA", "CH", "CP", "CS", "EC", "EN", "FB", "FP", "FR", "GA", "GH", "JA", "JG",
                            "JK", "KB", "LG", "MA", "MQ", "MV", "OF", "OH", "QV", "SC", "UP", "WF", "YO", "YU"])

def lambda_handler1():
    try:
        #with open(r"C:\Users\mjper\OneDrive\Documents\MTA\Operator Awareness Tool (OWARE)\Sample of Bus Vehicle Diagnostics and GPS log from Clever Devices IVN system\CleverWare0000323240107.txt.zip", 'rb') as f:
        #    file = f
        #obj = {"Body": file}
        obj = {"Body": open(r"C:\Users\mjper\OneDrive\Documents\MTA\Operator Awareness Tool (OWARE)\Sample of Bus Vehicle Diagnostics and GPS log from Clever Devices IVN system\CleverWare0000323240107.txt.zip", 'rb')}
        with io.BytesIO(obj["Body"].read()) as tf:
            # rewind the file
            tf.seek(0)

            # Read the file as a zipfile and process the members
            with zipfile.ZipFile(tf, mode='r') as zipf:
                for file in zipf.infolist():
                    fileName = file.filename
                    print(fileName)
                    #putFile = s3.put_object(Bucket=bucket2, Key=fileName, Body=zipf.read(file))
                    #putObjects.append(putFile)
                    #print(putFile)
                    unpacked = open('test.txt', 'w')
                    unpacked.write(zipf.read(file).decode('utf-16'))
                    unpacked.close()
                    return {'Key': fileName, 'Body': zipf.read(file)}

    except Exception as e:
        print(e)
        raise e

def lambda_handler2():
    resp = lambda_handler1()
    key=resp['Key']
    # Remove .txt from key name
    key2 = key.replace('.txt', '')
    x = resp['Body'].decode('utf-16')
    count = x.count('\r\n')+1

    df = pd.concat([chunk for chunk in tqdm(pd.read_csv(io.StringIO(x), sep='|', header=None, chunksize=1000), desc='Loading data', total=count)])

    # Open file as CSV
    #df = pd.read_csv(x, sep='|', header=None)
    
    # Name Columns
    df.columns = ['Date', 'Time', 'Event', 'Application', 'Module', 'Lat', 'Long', 'Heading', 'Speed',
                  '0', '1', '2', '3', '4', '5', 'Status']
    # Drop Columns
    df.drop(['0', '1', '2', '3', '4', '5'], inplace=True, axis=1)
    
    # Extract Framework Module
    df_framework = df[df["Module"] == 'Framework']
    
    # Get VehicleId
    #result = df_framework[df_framework['Status'].str.contains("VehicleId=")]
    #result = result.reset_index()
    #bus_id = result.at[0, "Status"].replace('VehicleId=', '')
    bus_id = int(key2[13:17].replace('.txt', ''))
    print(f"Vehicle ID: {bus_id}")
    
    # Change time to datetime format
    x = pd.to_datetime(df_framework['Date'] + ' ' + df_framework['Time'])
    df_framework = df_framework.copy()
    df_framework['DateTime'] = x
    
    # Round time to second
    lst = []
    for ts in df_framework['DateTime']:
        ts = ts.round(freq='S')
        lst.append(ts)
    df_framework['DateTime'] = lst
    
    # Get Date in Cleverware file
    date_test = df_framework['Date'].unique()
    valid_dates = [d for d in date_test if pd.to_datetime(d, errors='coerce') is not pd.NaT]
    
    # Get Bus Operator
    bus_operator = []
    dict = {}
    for i in valid_dates:
        #print(i)
        response = requests.get(url.format(i))
        x = response.text
        rawData = pd.read_csv(io.StringIO(x))
        # Change rows to datetime format
        rawData['Scheduled PO'] = pd.to_datetime(rawData['Scheduled PO'] + ' ' + i)
        rawData['Actual PO'] = pd.to_datetime(rawData['Actual PO'] + ' ' + i)
        rawData['Scheduled PI'] = pd.to_datetime(rawData['Scheduled PI'] + ' ' + i)
        rawData['Actual PI'] = pd.to_datetime(rawData['Actual PI'] + ' ' + i)
        # Change Bus column to string
        rawData['Bus'] = rawData['Bus'].astype("string")
        # Get rows with Bus ID
        #get_row_test = rawData[rawData['Bus'].str.match(bus_id)]
        get_row_test = rawData[rawData['Bus'].str.match(str(bus_id))]
        if get_row_test.shape[0] > 0:
            # Drop asterisk
            row_test = get_row_test[~get_row_test['Operator'].str.contains('\*')]
            # Reset Index
            index_reset = row_test.reset_index()
            # Add operator
            for index, row in index_reset.iterrows():
                dict[row['Operator']] = [row['Actual PO'], row['Actual PI'], row['UTS Depot']]
        else:
            print("Time or Bus ID don't match between yard-express and Cleverware log. Please check your file and try again.")
    
    for i in dict:
        # Capture time between scheduled_PI and scheduled_PO
        mask = (df_framework['DateTime'] >= dict[i][0]) & (df_framework['DateTime'] <= dict[i][1])
        df_filtered = df_framework.loc[mask]
        df_copy = df_filtered.copy()
        # Add operator, depot column to framework dataframe
        df_copy["Operator"] = i
        df_copy["UTS Depot"] = dict[i][2]
        # Drop rows with empty cells
        df_copy = df_copy.dropna()
        # Speed Calculations from ft/s to mph
        df_copy['Speed'] = df_copy['Speed'] * 0.681818
        # Calculate time difference between rows
        df_copy['Time_Diff'] = df_copy['DateTime'].diff().dt.total_seconds()
        # Drop rows where time diff < 0
        df_copy = df_copy[df_copy['Time_Diff'] > 0]
        df_copy2 = df_copy.assign(
            Acceleration=df_copy['Speed'].diff() / df_copy['DateTime'].diff().dt.total_seconds())
        # Set index as UTS Depot
        df_copy2 = df_copy2.set_index("UTS Depot")
        joined_df = df_copy2.join(depot)
        joined_df.index.name = 'UTS Depot'
        joined_df['UTSDepot'] = joined_df.index
        # Drop columns
        joined_df = joined_df.drop(['Date', 'Time', 'Event', 'Application', 'Module', 'Status', 'Time_Diff'], axis=1)
        joined_df.fillna(0.0, inplace=True)
        # Drop empty dataframe
        if joined_df.shape[0] > 0:
            joined_df['Bus_ID'] = bus_id
            if 1527 <= int(bus_id) <= 2716:
                joined_df = joined_df[joined_df['Speed'] <= 60]
                # Upload Dataframe to s3
                csv_buffer = StringIO()
                joined_df.to_csv(csv_buffer, index=False)
                # Change Bucket  and Key
                s3.put_object(Body=csv_buffer.getvalue(), Bucket='mtabuslogs-curated-rev2',
                              Key='{}-{}-cleverwaredata.csv'.format(key2, i))
                print("Parsing Complete")
                print(f'This is an Express bus with Bus ID: {bus_id}')
            else:
                joined_df = joined_df[joined_df['Speed'] <= 40]
                # Upload Dataframe to s3
                csv_buffer = StringIO()
                joined_df.to_csv(csv_buffer, index=False)
                # Change Bucket  and Key
                s3.put_object(Body=csv_buffer.getvalue(), Bucket='mtabuslogs-curated-rev2',
                              Key='{}-{}-cleverwaredata.csv'.format(key2, i))
                print("Parsing Complete")
                print(f'This is not an Express bus with Bus ID: {bus_id}')
        else:
            print("DataFrame is empty, export to s3 skipped.")

if __name__=='__main__':
    lambda_handler2()